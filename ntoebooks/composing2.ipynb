{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# Access the API key from the environment\n",
    "api_key = os.getenv(\"REPLICATE_API_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: ReplicateError Details:\n",
      "title: Free time limit reached\n",
      "status: 402\n",
      "detail: You have reached the free time limit. To continue using Replicate, set up billing at https://replicate.com/account/billing#billing.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# We use this variable to control where you want to host LLaVA, locally or remotely?\n",
    "# More details in the two setup options below.\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "from termcolor import colored\n",
    "\n",
    "import autogen\n",
    "from autogen import Agent, AssistantAgent, ConversableAgent, UserProxyAgent\n",
    "from autogen.agentchat.contrib.llava_agent import LLaVAAgent, llava_call\n",
    "\n",
    "LLAVA_MODE = \"remote\"  # Either \"local\" or \"remote\"\n",
    "assert LLAVA_MODE in [\"local\", \"remote\"]\n",
    "\n",
    "if LLAVA_MODE == \"remote\":\n",
    "    import replicate\n",
    "\n",
    "    llava_config_list = [\n",
    "        {\n",
    "            \"model\": \"yorickvp/llava-13b \",  # The model name doesn't matter here right now.\n",
    "            \"api_key\": api_key,  # Note that you have to setup the API key with os.environ[\"REPLICATE_API_TOKEN\"]\n",
    "            \"base_url\": \"yorickvp/llava-13b:2facb4a474a0462c15041b78b1ad70952ea46b5ec6ad29583c0b29dbd4249591\",\n",
    "        }\n",
    "    ]\n",
    "\n",
    "\n",
    "# rst = llava_call(\n",
    "#     \"Describe this AutoGen framework <img https://th.bing.com/th/id/R.422068ce8af4e15b0634fe2540adea7a?rik=y4OcXBE%2fqutDOw&pid=ImgRaw&r=0.png> with bullet points.\",\n",
    "#     llm_config={\"config_list\": llava_config_list, \"temperature\": 0},\n",
    "# )\n",
    "\n",
    "# print(rst)\n",
    "rst = llava_call(\n",
    "    \"\"\"based on this Categories [\n",
    "    Categories\n",
    "    1. Background Image\n",
    "    2. Logo\n",
    "    3. Call-To-Action (CTA) Button\n",
    "    4. Icon\n",
    "    5. Product Image\n",
    "    6. Text Elements\n",
    "    7. Infographic\n",
    "    8. Banner\n",
    "    9. Illustration\n",
    "    10. Photograph\n",
    "    11. Mascot\n",
    "    12. Testimonial Quotes\n",
    "    13. Social Proof\n",
    "    14. Seal or Badge\n",
    "    15. Graphs and Charts\n",
    "    16. Decorative Elements\n",
    "    17. Interactive Elements\n",
    "    18. Animation Frames\n",
    "    19. Coupon or Offer Code\n",
    "    20. Legal Disclaimers or Terms\n",
    "    21. Contact Information\n",
    "    22. Map or Location Image\n",
    "    23. QR Code]classify this <img ../image for test/content3.png>.\"\"\",\n",
    "    llm_config={\"config_list\": llava_config_list, \"temperature\": 0},\n",
    ")\n",
    "\n",
    "print(rst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending message to image agent:\n",
      "Using the following 3 images, make a storyboard of 3 frames by writing a code :\n",
      "<img ../src/image/cheese.png>\n",
      "\n",
      "\u001b[33mUser_proxy\u001b[0m (to image-creator):\n",
      "\n",
      "Using the following 3 images, make a storyboard of 3 frames by writing a code :\n",
      "<image>\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[34mYou are an AI agent and you can view images.\n",
      "###Human: Using the following 3 images, make a storyboard of 3 frames by writing a code :\n",
      "<image>\n",
      "\n",
      "\n",
      "###Assistant: \u001b[0m\n",
      "Error: ReplicateError Details:\n",
      "title: Free time limit reached\n",
      "status: 402\n",
      "detail: You have reached the free time limit. To continue using Replicate, set up billing at https://replicate.com/account/billing#billing.\n",
      "An error occurred: object of type 'NoneType' has no len()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the agents\n",
    "image_agent = LLaVAAgent(\n",
    "    name=\"image-creator\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    llm_config={\"config_list\": llava_config_list, \"temperature\": 0, \"max_new_tokens\": 1000},\n",
    ")\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User_proxy\",\n",
    "    system_message=\"A human admin.\",\n",
    "    code_execution_config={\n",
    "        \"last_n_messages\": 3,\n",
    "        \"work_dir\": \"coding\",\n",
    "        \"use_docker\": False,\n",
    "    },\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=0,\n",
    ")\n",
    "\n",
    "# Set the input and output directories\n",
    "input_dir = \"../src/image\"\n",
    "output_dir = \"output_test\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Collect image paths\n",
    "image_paths = list(Path(input_dir).glob(\"*\"))\n",
    "if len(image_paths) < 3:\n",
    "    raise ValueError(\"Not enough images in the input directory to create a storyboard. At least 3 images are required.\")\n",
    "\n",
    "# Randomly select three images\n",
    "selected_images = random.sample(image_paths, 3)\n",
    "\n",
    "# Create a message including the paths of the selected images\n",
    "message1 = \"Using the following 3 images, make a storyboard of 3 frames by writing a code :\\n\"\n",
    "for image_path in selected_images:\n",
    "    message =message1 + f\"<img {image_path}>\\n\"\n",
    "\n",
    "# Send the images to the image_agent for classification\n",
    "try:\n",
    "    print(f\"Sending message to image agent:\\n{message}\")\n",
    "    \n",
    "    response = user_proxy.initiate_chat(\n",
    "        image_agent,\n",
    "        message=message\n",
    "    )\n",
    "\n",
    "    print(f\"Response from image agent: {response}\")\n",
    "    \n",
    "except Exception as e:  \n",
    "\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w12_automated_storyboard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
